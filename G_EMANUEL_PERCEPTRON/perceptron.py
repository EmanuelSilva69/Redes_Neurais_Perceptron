# -*- coding: utf-8 -*-
"""perceptron.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/184SJkYJu3Une2zgTSvDSNdx8Arn0o9YX

# Atividade de Redes Neurais de Emanuel Lopes Silva

Este notebook foi desenvolvido como um guia te√≥rico e pr√°tico introdut√≥rio sobre Redes Neurais Artificiais (RNAs), com o objetivo de apresentar os conceitos fundamentais e exemplos de implementa√ß√£o em Python de forma clara e acess√≠vel.

As Redes Neurais Artificiais s√£o sistemas computacionais inspirados na estrutura e no funcionamento do c√©rebro humano. Elas utilizam unidades chamadas neur√¥nios artificiais, organizadas em camadas e interconectadas por pesos sin√°pticos, os quais s√£o ajustados automaticamente durante o aprendizado. Com isso, as RNAs s√£o capazes de identificar padr√µes, realizar classifica√ß√µes e fazer previs√µes com base em dados, sendo amplamente utilizadas em diversas aplica√ß√µes da intelig√™ncia artificial.

#1. Introdu√ß√£o ao modelo de Perceptron

##1.1. O que √© o Perceptron?

###1.1.1 Defini√ß√£o e prop√≥sito

O Perceptron √© considerado o primeiro modelo computacional de rede neural com capacidade de aprendizado supervisionado, sendo formulado por Frank Rosenblatt, em 1958. Seu objetivo era simular o processo de reconhecimento de padr√µes por organismos biol√≥gicos, estabelecendo uma liga√ß√£o entre a estrutura neural e o comportamento adaptativo. Segundo Rosenblatt, o Perceptron √© um "modelo probabil√≠stico de organiza√ß√£o e armazenamento de informa√ß√£o no c√©rebro", cuja fun√ß√£o central √© aprender a associar padr√µes de entrada a respostas esperadas com base em exemplos fornecidos previamente (ROSENBLATT, 1958).

Seu prop√≥sito pode ser simplificado nos seguintes pontos:
- Simular o processo de **aprendizado supervisionado** inspirado no c√©rebro humano.
- Estabelecer um **modelo matem√°tico** capaz de reconhecer padr√µes a partir de exemplos.
- Demonstrar que √© poss√≠vel implementar **fun√ß√µes de decis√£o lineares** com neur√¥nios artificiais simples.
- Investigar como a **informa√ß√£o √© armazenada e organizada** em redes de conex√µes sin√°pticas.
- Propor um sistema que aprende ajustando **pesos sin√°pticos** com base no erro da resposta.
- Oferecer uma base te√≥rica para a constru√ß√£o de redes neurais mais complexas no futuro.
- Explorar o potencial de redes com **unidades simples interconectadas** para gerar comportamento inteligente.

###1.1.2 Origem Hist√≥rica

A origem do modelo de Perceptron remonta √† tentativa de compreender os mecanismos de aprendizagem e reconhecimento presentes nos sistemas nervosos biol√≥gicos. O trabalho seminal de McCulloch e Pitts (1943) j√° propunha uma estrutura l√≥gica para descrever a atividade neural por meio de fun√ß√µes booleanas, estabelecendo os fundamentos do que viria a ser conhecido como redes neurais artificiais. Eles demonstraram que "a atividade de qualquer neur√¥nio pode ser representada como uma proposi√ß√£o" e que redes neurais poderiam, em princ√≠pio, implementar qualquer fun√ß√£o l√≥gica comput√°vel com base em conex√µes sin√°pticas e limiares de ativa√ß√£o‚Äã.

D√©cadas depois, Frank Rosenblatt, em seu artigo de 1958, formalizou o modelo do Perceptron como uma m√°quina probabil√≠stica capaz de realizar tarefas de classifica√ß√£o por meio da aprendizagem dos pesos sin√°pticos. Segundo Rosenblatt, o Perceptron representa um "sistema nervoso hipot√©tico" que armazena informa√ß√£o por meio de conex√µes modific√°veis, sendo capaz de generalizar e reconhecer padr√µes com base em est√≠mulos sensoriais‚Äã
. Esse modelo √© considerado a primeira implementa√ß√£o pr√°tica de uma rede neural com capacidade de aprendizado supervisionado.

O entusiasmo inicial com o Perceptron, no entanto, foi confrontado com cr√≠ticas importantes. O livro Perceptrons de Minsky e Papert (1969) demonstrou limita√ß√µes fundamentais do modelo, especialmente sua incapacidade de resolver problemas n√£o linearmente separ√°veis, como o XOR. Essa cr√≠tica desacelerou o avan√ßo das redes neurais por quase duas d√©cadas.

Somente nos anos 1980, com o trabalho de Rumelhart, Hinton e McClelland, foi poss√≠vel revitalizar o campo por meio do conceito de Parallel Distributed Processing (PDP). Esses pesquisadores defenderam que o processamento inteligente poderia emergir da intera√ß√£o paralela de unidades simples de processamento, refor√ßando o papel das redes distribu√≠das e do aprendizado supervisionado por propaga√ß√£o do erro como alternativa vi√°vel e biologicamente plaus√≠vel para modelar a cogni√ß√£o humana‚Äã
.

###1.1.3 Import√¢ncia na evolu√ß√£o das redes neurais
O modelo do Perceptron teve um papel fundamental na hist√≥ria da Intelig√™ncia Artificial, sendo considerado o ponto de partida das redes neurais artificiais com capacidade de aprendizado. Proposto por Frank Rosenblatt em 1958, o Perceptron foi o primeiro sistema computacional que demonstrou ser poss√≠vel ensinar uma m√°quina a reconhecer padr√µes por meio de ajustes iterativos em seus par√¢metros internos, simulando o processo de aprendizagem observado em sistemas biol√≥gicos (ROSENBLATT, 1958).

Seu funcionamento baseado na atualiza√ß√£o de pesos sin√°pticos a partir do erro da sa√≠da contribuiu para consolidar o paradigma conexionista como alternativa aos modelos simb√≥licos dominantes na √©poca.

Ele foi essencial na evolu√ß√£o das redes neurais, pois:

- Foi o primeiro modelo de rede neural com capacidade de aprendizado supervisionado.
- Estabeleceu a ideia de ajuste de pesos sin√°pticos como mecanismo de aprendizagem.
- Inspirou o desenvolvimento de redes neurais multicamadas (MLPs) e o uso da retropropaga√ß√£o.
- Sua limita√ß√£o com problemas como XOR motivou pesquisas sobre redes com maior capacidade expressiva.
- Fundamentou a transi√ß√£o de modelos simb√≥licos para modelos conexionistas na IA.
- Tornou-se refer√™ncia obrigat√≥ria em estudos sobre o surgimento das redes neurais profundas.

##1.2. Inspira√ß√£o Biol√≥gica
O Perceptron foi inspirado diretamente na estrutura e funcionamento dos neur√¥nios biol√≥gicos, buscando representar, de maneira simplificada, o comportamento das c√©lulas nervosas presentes no c√©rebro humano.

###1.2.1 Compara√ß√£o entre neur√¥nios biol√≥gicos e artificiais

No sistema nervoso biol√≥gico, os neur√¥nios recebem sinais de entrada por meio de estruturas chamadas dendritos, que conduzem impulsos el√©tricos at√© o corpo celular (soma). Quando o potencial el√©trico resultante ultrapassa um certo limiar, o neur√¥nio dispara um impulso atrav√©s do ax√¥nio, transmitindo a informa√ß√£o a outras c√©lulas por meio de sinapses.

J√° no modelo do Perceptron, essa din√¢mica √© representada de forma simplificada: os sinais de entrada (an√°logos aos impulsos recebidos pelos dendritos) s√£o multiplicados por pesos sin√°pticos, somados, e ent√£o processados por uma fun√ß√£o de ativa√ß√£o, que determina a sa√≠da do neur√¥nio artificial, muitas vezes de forma bin√°ria. A fun√ß√£o de ativa√ß√£o desempenha o papel do disparo ou n√£o do potencial de a√ß√£o no neur√¥nio biol√≥gico.

Embora os neur√¥nios artificiais n√£o capturem toda a complexidade bioqu√≠mica e eletrofisiol√≥gica dos neur√¥nios reais, sua estrutura matem√°tica √© suficiente para representar opera√ß√µes computacionais fundamentais, especialmente no contexto de aprendizado supervisionado e reconhecimento de padr√µes. Essa analogia simplificada permitiu o desenvolvimento de redes neurais artificiais como modelos computacionais inspirados no c√©rebro, mas adaptados √†s necessidades da computa√ß√£o digital.

###1.2.2 Elementos equivalentes: dendritos, corpo celular, ax√¥nio, sinapse
No processo de abstra√ß√£o que originou os neur√¥nios artificiais, alguns dos principais componentes do neur√¥nio biol√≥gico foram mapeados para elementos matem√°ticos com fun√ß√µes equivalentes no modelo computacional.

Os dendritos, que nos neur√¥nios biol√≥gicos recebem sinais el√©tricos de outras c√©lulas, correspondem √†s entradas do neur√¥nio artificial. Cada uma dessas entradas √© multiplicada por um valor chamado peso sin√°ptico, que simula a for√ßa da conex√£o entre os neur√¥nios.

O corpo celular (soma), respons√°vel por integrar os sinais recebidos e decidir se o neur√¥nio deve disparar, √© representado por uma fun√ß√£o de soma ponderada nos modelos artificiais.

J√° o ax√¥nio, que transmite o impulso el√©trico do corpo celular para outros neur√¥nios, corresponde √† sa√≠da do neur√¥nio artificial.

Por fim, as sinapses, que regulam a passagem de sinais entre neur√¥nios e podem ser fortalecidas ou enfraquecidas com o tempo, s√£o modeladas pelos pr√≥prios pesos ajust√°veis, que s√£o modificados durante o processo de aprendizado para otimizar a resposta do modelo.
##1.3. Estrutura de um Perceptron
O Perceptron √© um modelo simples, por√©m fundamental, de neur√¥nio artificial. Ele realiza uma decis√£o bin√°ria com base em uma combina√ß√£o linear das entradas, seguida por uma fun√ß√£o de ativa√ß√£o. Abaixo est√£o seus componentes principais:

- Entradas ùë•ùëñ: Valores num√©ricos de entrada do modelo (por exemplo, caracter√≠sticas de um dado).

- Pesos ùë§ùëñ: Cada entrada est√° associada a um peso, que indica sua import√¢ncia no c√°lculo da sa√≠da.

- Bias (vi√©s) ùëè: Um valor adicional que ajusta a sa√≠da independentemente das entradas, deslocando a fun√ß√£o de ativa√ß√£o.

- Somat√≥rio ùë¢: O valor de ativa√ß√£o intermedi√°rio \( u \), antes de passar pela fun√ß√£o de ativa√ß√£o, √© calculado pela soma ponderada das entradas com seus respectivos pesos, mais o vi√©s (bias):

$$
u = \sum_{i=1}^{n} w_i \cdot x_i + b
$$
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Onde, nessa formula, al√©m das vari√°veis anterioresm existe o "n", que √© o n√∫mero total de entradas.

- Fun√ß√£o de ativa√ß√£o (limiar):
A sa√≠da do Perceptron \( y \) √© determinada pela fun√ß√£o de ativa√ß√£o do tipo degrau (step function):

$$
f(u) =
\begin{cases}
1, & \text{se } u \geq 0 \\
0, & \text{se } u < 0
\end{cases}
$$

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Assim, a sa√≠da final √©:

$$
y = f(u)
$$

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Essa fun√ß√£o simula o comportamento "tudo ou nada" dos neur√¥nios biol√≥gicos.

- Sa√≠da bin√°ria (0 ou 1): Como foi mencionado logo anteriormente, a sa√≠da de um Perceptron √© bin√°ria, ou seja, assume apenas dois valores poss√≠veis: 0 ou 1. Essa caracter√≠stica est√° diretamente relacionada √† fun√ß√£o de ativa√ß√£o utilizada, que normalmente √© a fun√ß√£o degrau (step function).

###1.3.1 Esquema visual do neur√¥nio Perceptron
"""

import matplotlib.pyplot as plt
import matplotlib.patches as patches

# Criar a figura
fig, ax = plt.subplots(figsize=(13, 7))
ax.set_xlim(0, 15)
ax.set_ylim(2, 12)
ax.axis('off')  # remove os eixos

# === Entradas ponderadas ===
entradas = [r"$x_1 \cdot w_1$", r"$x_2 \cdot w_2$", r"$x_3 \cdot w_3$", r"$x_4 \cdot w_4$", r"$x_5 \cdot w_5$"]
y_coords = [10.5, 9, 7.5, 6, 4.5]

for i, y in enumerate(y_coords):
    ax.text(0.5, y, entradas[i], fontsize=14, ha='left')
    ax.plot([3, 6], [y, 6.5], 'k', lw=2)
    ax.plot(3, y, 'ko')  # ponto de origem

# === Colchete lateral "Inputs" ===
ax.plot([0.2, 0.2], [4.2, 10.8], 'k', lw=1.8)
ax.plot([0.2, 0.5], [10.8, 10.8], 'k', lw=1.8)
ax.plot([0.2, 0.5], [4.2, 4.2], 'k', lw=1.8)
ax.text(-0.2, 7.5, "Inputs", rotation=90, fontsize=12, va='center')

# === Bias ===
ax.arrow(4.0, 3, 2.0, 3.3, head_width=0.2, head_length=0.3, fc='dimgray', ec='dimgray', linestyle='--')
ax.text(3.4, 2.9, r"$+b$", fontsize=13, color='dimgray')

# === C√≠rculo azul (neur√¥nio somador) ===
neuron = patches.Circle((6, 6.5), 0.8, edgecolor='black', facecolor='#00B4D8', lw=2, zorder=10)
ax.add_patch(neuron)
ax.text(6, 6.5, r"$\sum$", ha='center', va='center', fontsize=18, zorder=11)

# === Bloco da fun√ß√£o de ativa√ß√£o (EM CIMA DA LINHA) ===
activation = patches.FancyBboxPatch((7.5, 5.75), 3, 1.5, boxstyle="round,pad=0.2",
                                    edgecolor='black', facecolor='#b5f0b6', lw=2)
ax.add_patch(activation)
ax.text(9.0, 6.5,
        "f(u) = 1 se u ‚â• 0\nf(u) = 0 se u < 0",
        ha='center', va='center', fontsize=11, family='monospace')

# === Linha do somador at√© ativa√ß√£o (por baixo da caixa)
ax.plot([6.8, 7.5], [6.5, 6.5], 'k', lw=2)

# === Linha da ativa√ß√£o at√© a sa√≠da
ax.plot([10.5, 12], [6.5, 6.5], 'k', lw=2)
ax.plot(12, 6.5, 'ko')
ax.text(12.2, 6.5, r"$y$", fontsize=14, va='center')
ax.text(12.2, 6.1, r"(0 or 1)", fontsize=11, va='top')

# === F√≥rmulas explicativas abaixo ===
ax.text(3.5, 1.3, r"$u = \sum_{i=1}^{n} x_i w_i + b$", fontsize=15)


# T√≠tulo
plt.title("Perceptron: Fun√ß√£o de Ativa√ß√£o sobre a Linha de Sa√≠da", fontsize=15, pad=20)

plt.show()

"""##1.4. Funcionamento B√°sico
Etapas do processo:

 ### Soma ponderada

Nesta primeira etapa, o Perceptron realiza o c√°lculo de uma soma ponderada entre as entradas ùë•ùëñ e os respectivos pesos sin√°pticos ùë§ùëñ, adicionando ainda um termo de vi√©s (bias) ùëè. O objetivo √© combinar todas as informa√ß√µes de entrada em um √∫nico valor num√©rico que ser√° usado para tomar a decis√£o.

A formula utilizada √©:
$
u = \sum_{i=1}^{n} x_i \cdot w_i + b
$
, onde:

ùë•
ùëñ
: entrada
ùëñ

ùë§
ùëñ‚Äã
 : peso associado √† entrada

ùëè: bias (vi√©s), valor fixo que desloca a fronteira de decis√£o

ùë¢: resultado da soma ponderada

Este valor ùë¢ representa a ativa√ß√£o l√≠quida do neur√¥nio, ou seja, o quanto o neur√¥nio est√° estimulado a "disparar".

 ### Aplica√ß√£o da fun√ß√£o de ativa√ß√£o

Ap√≥s o c√°lculo da ativa√ß√£o l√≠quida
ùë¢, o Perceptron aplica uma fun√ß√£o de ativa√ß√£o, geralmente a fun√ß√£o degrau (step function). Essa fun√ß√£o √© respons√°vel por transformar
ùë¢ em uma sa√≠da bin√°ria ‚Äî ou seja, decidir se o neur√¥nio ser√° ativado (1) ou n√£o (0).

A fun√ß√£o de ativa√ß√£o usada no Perceptron cl√°ssico √© definida como:

$
f(u) =
\begin{cases}
1, & \text{se } u \geq 0 \\
0, & \text{se } u < 0
\end{cases}
$

Essa fun√ß√£o simula o comportamento de "tudo ou nada" dos neur√¥nios biol√≥gicos: o neur√¥nio s√≥ dispara (ativa) se a soma ponderada for suficiente (maior ou igual ao limiar, que normalmente √© zero).

- Gera√ß√£o da sa√≠da

O resultado da fun√ß√£o de ativa√ß√£o,
ùë¶=ùëì(ùë¢), √© a sa√≠da final do Perceptron. Essa sa√≠da √© um valor discreto e bin√°rio:

 ùë¶=1: o Perceptron est√° ativado, ou seja, considera que a entrada pertence √† classe positiva.

 ùë¶=0: o Perceptron n√£o est√° ativado, indicando a classe negativa.

##1.5. F√≥rmulas Matem√°ticas
 ###  Multiplica√ß√£o Matricial/Vetorial

 O c√°lculo da sa√≠da do Perceptron pode ser representado como uma multiplica√ß√£o vetorial, onde as entradas $ \mathbf{x} $ s√£o multiplicadas pelos pesos $ \mathbf{w} $:

$
u = \mathbf{w}^\top \cdot \mathbf{x} + b
$

Ou seja, expandindo:

$
u = w_1 x_1 + w_2 x_2 + \dots + w_n x_n + b = \sum_{i=1}^{n} w_i x_i + b
$

Esse valor $ u $ √© ent√£o passado pela fun√ß√£o de ativa√ß√£o para produzir a sa√≠da $ y $.

---
 ###  Fun√ß√£o de Custo

 No Perceptron cl√°ssico, a fun√ß√£o de custo mais simples e utilizada no treinamento √© o erro absoluto entre a sa√≠da desejada e a sa√≠da predita pelo modelo.

A f√≥rmula √© dada por:

$
E = y_{\text{desejado}} - y_{\text{predito}}
$

Onde:

- $ E > 0 $: O Perceptron subestimou a sa√≠da ‚Üí precisa aumentar os pesos.
- $ E < 0 $: O Perceptron superestimou ‚Üí precisa reduzir os pesos.
- $ E = 0 $: Classifica√ß√£o correta ‚Üí nenhuma atualiza√ß√£o √© necess√°ria.

Essa fun√ß√£o de erro √© usada diretamente na regra de atualiza√ß√£o dos pesos, de forma simples e eficiente, ideal para problemas linearmente separ√°veis.

  ###  Regra de Atualiza√ß√£o dos Pesos e Bias

 A regra de atualiza√ß√£o dos pesos √© o cora√ß√£o do aprendizado do Perceptron. Quando h√° erro, os pesos s√£o atualizados da seguinte forma:


$ w_i \leftarrow w_i + \eta \cdot (y_{\text{real}} - y) \cdot x_i $

E o **bias** √© atualizado da mesma forma:


$
b \leftarrow b + \eta \cdot (y_{\text{real}} - y)
$

Onde:
-
$ \eta
$: taxa de aprendizado (learning rate)
-
$ y_{\text{real}}
$: sa√≠da esperada
-
$ y
$: sa√≠da prevista pelo modelo
-
$ x_i
$: entrada associada ao peso
$ w_i
$

Esse processo se repete para cada amostra durante o treinamento, ajustando os pesos at√© que o Perceptron classifique corretamente (ou at√© atingir o n√∫mero m√°ximo de √©pocas).


##1.6. Algoritmo de Aprendizado do Perceptron
 ### L√≥gica do treinamento supervisionado

O Perceptron √© treinado com exemplos rotulados ‚Äî ou seja, cada entrada $ \mathbf{x} $ vem acompanhada da sa√≠da esperada $ y_{\text{real}} $. O modelo realiza uma previs√£o $ y_{\text{previsto}} $, e compara com a resposta correta. Se houver erro, os pesos s√£o ajustados.

 ###  Atualiza√ß√£o dos pesos:

Durante o treinamento supervisionado, o Perceptron aprende ajustando seus pesos com base nos erros que comete ao comparar a sa√≠da prevista com a sa√≠da real (esperada).

A regra de atualiza√ß√£o tem como objetivo **corrigir os pesos sin√°pticos $ w_i $ e o bias $ b $ para que o modelo acerte nas pr√≥ximas previs√µes.

 ### Papel da taxa de aprendizado ùúÇ:

A taxa de aprendizado define a velocidade do ajuste:

- Pequena $ \eta \approx 0.01 $ ‚Üí mudan√ßas suaves, aprendizado est√°vel por√©m lento
- Grande $ \eta \approx 1.0 $ ‚Üí mudan√ßas r√°pidas, por√©m pode causar oscila√ß√µes e n√£o convergir
> obs:
>- Se $ \eta $ for **muito alta**, os ajustes podem ser exagerados e causar instabilidade.
> - Se $ \eta $ for **muito baixa**, o modelo aprende devagar e pode n√£o atingir a solu√ß√£o ideal em tempo h√°bil.
> - Valores comuns: $ \eta = 0.1 $, $ \eta = 0.01 $

O valor de $ \eta $ precisa ser bem escolhido para garantir que o Perceptron converja corretamente, ou seja, aprenda os padr√µes dos dados sem instabilidade.

##1.7. Converg√™ncia e Limita√ß√µes
 ### Converg√™ncia garantida para problemas linearmente separ√°veis

O algoritmo do Perceptron possui uma propriedade importante: se os dados forem linearmente separ√°veis, ou seja, se existir uma linha (ou plano/hiperplano) que divida perfeitamente as classes, ent√£o o Perceptron ir√° convergir em um n√∫mero finito de itera√ß√µes.

Isso significa que ele ir√° encontrar os pesos corretos para classificar todas as amostras corretamente.

Matematicamente, isso foi provado pelo Teorema de Converg√™ncia do Perceptron, que afirma que:

> Se existe um vetor de pesos que separa as classes, o algoritmo do Perceptron o encontrar√° ap√≥s um n√∫mero finito de atualiza√ß√µes.

 ### Limita√ß√µes do modelo simples (n√£o resolve o XOR)

Apesar da sua utilidade, o Perceptron simples (de uma camada) tem limita√ß√µes s√©rias. A principal √© que ele **n√£o consegue resolver problemas n√£o linearmente separ√°veis**.

Um exemplo cl√°ssico √© o problema l√≥gico XOR (ou exclusivo), onde:

- As classes n√£o podem ser separadas por uma linha reta
- N√£o existe combina√ß√£o linear de entradas que permita ao Perceptron simples aprender a fun√ß√£o

Ou seja:

> O Perceptron n√£o consegue aprender padr√µes que exigem decis√µes n√£o lineares.

 ### Introdu√ß√£o √† motiva√ß√£o para redes multicamadas
 A limita√ß√£o de resolver apenas problemas linearmente separ√°veis motivou a cria√ß√£o das redes neurais multicamadas, tamb√©m chamadas de MLPs (Multi-Layer Perceptrons).

Essas redes incluem uma ou mais camadas ocultas, que aplicam transforma√ß√µes n√£o lineares sobre os dados, permitindo que o modelo aprenda padr√µes mais complexos, como o caso do XOR.

As MLPs utilizam fun√ß√µes de ativa√ß√£o como:

- ReLU
- Sigmoide
- Tangente hiperb√≥lica

Al√©m disso, s√£o treinadas com algoritmos como o backpropagation, que permite ajustar pesos em v√°rias camadas de forma eficiente.


##1.8. Visualiza√ß√µes e Intui√ß√µes Geom√©tricas
###Fronteiras de decis√£o lineares:

O Perceptron √© um classificador linear, ou seja, ele toma decis√µes com base em uma fronteira linear no espa√ßo das entradas. Essa fronteira √© determinada pela equa√ß√£o da soma ponderada:

$u = \sum_{i=1}^{n} w_i x_i + b$

Aplicando a fun√ß√£o de ativa√ß√£o:

$y = f(u) =
\begin{cases}
1, & \text{se } u \geq 0 \\
0, & \text{se } u < 0
\end{cases}$

Essa equa√ß√£o define uma reta (em 2D), um plano (em 3D) ou um hiperplano (em dimens√µes superiores) que separa as classes.


###Separa√ß√£o de classes no plano cartesiano
Para problemas com duas entradas (ex: $x_1$ e $x_2$), o Perceptron pode ser visualizado **no plano cartesiano**. A fronteira de decis√£o ser√° uma **reta** dada por:

$w_1 x_1 + w_2 x_2 + b = 0$

Isolando $x_2$:

$x_2 = -\frac{w_1}{w_2} x_1 - \frac{b}{w_2}$

Essa √© a equa√ß√£o da **reta de separa√ß√£o**: divide o plano em duas regi√µes ‚Äî uma onde a sa√≠da ser√° 1 (classe positiva) e outra onde a sa√≠da ser√° 0 (classe negativa).


##1.9. Varia√ß√µes e Extens√µes

###Perceptron com m√∫ltiplos neur√¥nios (camada de sa√≠da com mais classes)
O Perceptron original foi projetado para resolver **problemas de classifica√ß√£o bin√°ria** (sa√≠da 0 ou 1). No entanto, ele pode ser estendido para resolver **problemas com mais de duas classes** utilizando uma **camada de sa√≠da com m√∫ltiplos neur√¥nios**.

Cada **neur√¥nio da camada de sa√≠da** √© respons√°vel por detectar uma **classe espec√≠fica**. O modelo ent√£o retorna a classe cuja **sa√≠da do neur√¥nio correspondente for a maior** (ou for 1, se usar codifica√ß√£o one-hot).

Dessa forma:
- 3 classes ‚Üí 3 neur√¥nios na sa√≠da
- Entrada $\mathbf{x}$ conectada a **cada neur√¥nio com pesos distintos**
- Sa√≠da: vetor $[y_1, y_2, y_3]$, onde apenas uma posi√ß√£o ser√° ativada

###Fun√ß√µes de ativa√ß√£o alternativas (ReLU, Sigmoid ‚Äì apenas para contextualizar)

Embora o Perceptron cl√°ssico use a **fun√ß√£o degrau**, redes neurais modernas utilizam fun√ß√µes de ativa√ß√£o cont√≠nuas e diferenci√°veis, essenciais para o treinamento com **backpropagation**.

####  Sigmoid

A fun√ß√£o sigmoid comprime o valor de entrada para o intervalo $(0, 1)$, sendo ideal para tarefas de probabilidade e classifica√ß√£o bin√°ria:

$
\sigma(x) = \frac{1}{1 + e^{-x}}
$

####  ReLU (Rectified Linear Unit)

Muito usada em redes profundas, a ReLU √© simples e eficaz. Ela zera valores negativos e mant√©m os positivos:

$
\text{ReLU}(x) = \max(0, x)
$

---

###  Observa√ß√£o

>Essas fun√ß√µes n√£o s√£o usadas no Perceptron original, mas s√£o fundamentais nas redes neurais modernas, como MLPs, CNNs e RNNs, pois permitem o uso de algoritmos baseados em derivadas.

#2. Aplica√ß√£o do Perceptron aos problemas l√≥gicos OR e AND

##2.1. Revis√£o dos Problemas L√≥gicos

O Perceptron pode ser aplicado a tarefas de classifica√ß√£o bin√°ria, como a reprodu√ß√£o do comportamento de operadores l√≥gicos. Dois dos exemplos mais cl√°ssicos s√£o as opera√ß√µes AND e OR, que envolvem entradas bin√°rias e geram uma sa√≠da tamb√©m bin√°ria.

###Tabelas verdade dos operadores l√≥gicos AND e OR
Fun√ß√£o AND:

| $x_1$ | $x_2$ | $ y$ = $x_1$ . $x_2$  |
|------:|------:|:------------------:|
|   0   |   0   |         0         |
|   0   |   1   |         0         |
|   1   |   0   |         0         |
|   1   |   1   |         1         |

A sa√≠da $y$ ser√° 1 somente quando ambas as entradas forem 1.  
A fun√ß√£o AND √© linearmente separ√°vel, ou seja, o Perceptron consegue aprender essa rela√ß√£o com uma reta de separa√ß√£o adequada.

Fun√ß√£o OR:

| $x_1$ | $x_2$ | $y$ = $x_1$ + $x_2$ |
|------:|------:|:------------------:|
|   0   |   0   |         0         |
|   0   |   1   |         1         |
|   1   |   0   |         1         |
|   1   |   1   |         1         |

A sa√≠da $y$ ser√° 1 se pelo menos uma entrada for 1.  
O problema OR tamb√©m √© linearmente separ√°vel, o que significa que existe uma reta no plano cartesiano que divide corretamente as classes.

###Representa√ß√£o como problemas de classifica√ß√£o bin√°ria
Nos dois casos, estamos lidando com um conjunto de entradas bin√°rias ($x_1$, $x_2$) e uma sa√≠da esperada bin√°ria ($y \in \{0,1\}$). Isso caracteriza um problema de classifica√ß√£o supervisionada com duas classes:

- Classe 0: sa√≠da negativa (falsa)  
- Classe 1: sa√≠da positiva (verdadeira)

Esses problemas s√£o exemplos ideais para treinar e avaliar o funcionamento do Perceptron simples, pois s√£o casos linearmente separ√°veis que permitem observar como os pesos s√£o ajustados e como o modelo converge.

##2.2. Constru√ß√£o Manual dos Datasets
###Conjunto de dados com entrada bin√°ria (0 ou 1)
Nos problemas l√≥gicos como AND e OR, as entradas s√£o sempre valores bin√°rios, ou seja, $x_1$ e $x_2$ assumem apenas os valores 0 ou 1. Como s√£o duas entradas poss√≠veis, podemos gerar todas as combina√ß√µes bin√°rias de entrada com:

- $x_1 \in \{0, 1\}$
- $x_2 \in \{0, 1\}$

As combina√ß√µes poss√≠veis s√£o:

- (0, 0)  
- (0, 1)  
- (1, 0)  
- (1, 1)
###Prepara√ß√£o dos pares (entrada, sa√≠da esperada)
O objetivo √© treinar o Perceptron para aprender a mapear as entradas bin√°rias para a sa√≠da correta, de acordo com o operador l√≥gico que estamos simulando (AND ou OR).

Cada amostra do conjunto de dados √© um par do tipo:

- Entrada: vetor $[x_1, x_2]$
- Sa√≠da esperada: $y_{\text{real}}$

- Para **AND**:

$
Y = \left[
\begin{array}{c}
0 \\
0 \\
0 \\
1 \\
\end{array}
\right]
$

- Para **OR**:

$
Y = \left[
\begin{array}{c}
0 \\
1 \\
1 \\
1 \\
\end{array}
\right]
$

---

### C√°lculo da Soma Ponderada

O Perceptron ir√° calcular a sa√≠da atrav√©s de uma soma ponderada das entradas com os pesos, somada a um bias $b$:

$$
u = \sum_{i=1}^{n} w_i \cdot x_i + b
$$

Para cada amostra, esse valor $u$ ser√° passado para uma fun√ß√£o de ativa√ß√£o do tipo degrau:

$$
f(u) =
\begin{cases}
1, & \text{se } u \geq 0 \\
0, & \text{se } u < 0
\end{cases}
$$

##2.3. Implementa√ß√£o do Perceptron
"""

import numpy as np
import matplotlib.pyplot as plt

# =============================
# Fun√ß√£o de ativa√ß√£o (degrau)
# =============================
def degrau(u):
    return 1 if u >= 0 else 0

# =============================
# Inicializa√ß√£o do dataset l√≥gico OR
# =============================
entradas = np.array([
    [0, 0],
    [0, 1],
    [1, 0],
    [1, 1]
])

# Sa√≠das esperadas para OR
saidas = np.array([0, 1, 1, 1])

# =============================
# Par√¢metros iniciais
# =============================
epocas = 20              # n√∫mero m√°ximo de √©pocas
eta = 0.01                # taxa de aprendizado
n_amostras, n_entradas = entradas.shape

# Inicializa√ß√£o dos pesos (zeros ou aleat√≥rios)
pesos = np.random.uniform(-1, 1, size=n_entradas)
bias = 0.0

# Hist√≥rico para visualiza√ß√£o
historico_pesos = []
historico_erro = []

# =============================
# Treinamento
# =============================
for epoca in range(epocas):
    erro_total = 0
    for i in range(n_amostras):
        x = entradas[i]
        y_real = saidas[i]

        # 1. Calcular a soma ponderada
        u = np.sum(pesos * x) + bias

        # 2. Aplicar fun√ß√£o de ativa√ß√£o
        y_pred = degrau(u)

        # 3. Calcular erro
        erro = y_real - y_pred
        erro_total += abs(erro)

        # 4. Atualizar pesos e bias
        for j in range(n_entradas):
            pesos[j] += eta * erro * x[j]
        bias += eta * erro

    # Armazena hist√≥rico
    historico_pesos.append(pesos.copy())
    historico_erro.append(erro_total)

    # Print da √©poca
    print(f"√âpoca {epoca+1}: Erro Total = {erro_total}")

    # Crit√©rio de parada: erro zero
    if erro_total == 0:
        print("Converg√™ncia atingida.")
        break

"""## 2.4. Gr√°fico de Converg√™ncia"""

import matplotlib.pyplot as plt
import numpy as np

# Converter o hist√≥rico de pesos para array
pesos_array = np.array(historico_pesos)

# Criar a figura com dois subgr√°ficos
plt.figure(figsize=(12, 5))

#  Erro total por √©poca
plt.subplot(1, 2, 1)
plt.plot(historico_erro, marker='o', color='red')
plt.title("Erro Total por √âpoca")
plt.xlabel("√âpoca")
plt.ylabel("Erro Total")
plt.grid(True)

#  Evolu√ß√£o dos pesos
plt.subplot(1, 2, 2)
for i in range(pesos_array.shape[1]):
    plt.plot(pesos_array[:, i], marker='o', label=f"$w_{i+1}$")
plt.title("Evolu√ß√£o dos Pesos")
plt.xlabel("√âpoca")
plt.ylabel("Valor dos Pesos")
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

"""##2.5. Avalia√ß√£o do Modelo


"""

print("\n=== Avalia√ß√£o do Modelo Treinado ===\n")

for i in range(len(entradas)):
    x = entradas[i]
    y_real = saidas[i]

    # Soma ponderada com os pesos finais
    u = np.sum(x * pesos) + bias

    # Previs√£o com a fun√ß√£o de ativa√ß√£o
    y_pred = degrau(u)

    # Impress√£o do resultado
    print(f"Entrada: {x} ‚Üí Sa√≠da esperada: {y_real} | Sa√≠da prevista: {y_pred}")

"""##2.6. Visualiza√ß√£o dos Resultados
###Gr√°ficos de dispers√£o dos dados
Cada ponto no gr√°fico representa uma amostra bin√°ria com coordenadas ($x_1$, $x_2$). Os pontos foram coloridos conforme sua classe esperada:

- Vermelho: sa√≠da esperada 0 (classe negativa)
- Azul: sa√≠da esperada 1 (classe positiva)


###Exibi√ß√£o da fronteira de decis√£o
A reta preta pontilhada representa a **fronteira de decis√£o aprendida pelo Perceptron**, calculada a partir da equa√ß√£o:

$w_1 x_1 + w_2 x_2 + b = 0$

Essa fronteira divide o plano em duas regi√µes:

- Acima da reta: pontos onde $y = 1$
- Abaixo da reta: pontos onde $y = 0$

###An√°lise visual: separabilidade linear

Se os pontos das duas classes estiverem em lados opostos da reta, o problema √© linearmente separ√°vel ‚Äî como nos casos de OR e AND.  
Se isso n√£o for poss√≠vel (como no caso do XOR), o Perceptron simples n√£o consegue encontrar uma reta que separe perfeitamente as classes, evidenciando sua limita√ß√£o.

"""

import matplotlib.pyplot as plt

# Preparar dados por classe para plotar com cores diferentes
classe_0 = entradas[saidas == 0]
classe_1 = entradas[saidas == 1]

# Criar a figura
plt.figure(figsize=(7, 6))

# Plotar os pontos de cada classe
plt.scatter(classe_0[:, 0], classe_0[:, 1], color='red', label='Classe 0 (Sa√≠da = 0)')
plt.scatter(classe_1[:, 0], classe_1[:, 1], color='blue', label='Classe 1 (Sa√≠da = 1)')

# T√≠tulo e r√≥tulos
plt.title("Dispers√£o dos Dados e Fronteira de Decis√£o do Perceptron")
plt.xlabel("$x_1$")
plt.ylabel("$x_2$")
plt.xlim(-0.1, 1.1)
plt.ylim(-0.1, 1.1)

# Plotar a fronteira de decis√£o (reta: w1*x1 + w2*x2 + b = 0)
# Isolar x2: x2 = -(w1/w2)*x1 - b/w2
if pesos[1] != 0:
    x1_vals = np.linspace(-0.1, 1.1, 100)
    x2_vals = -(pesos[0] * x1_vals + bias) / pesos[1]
    plt.plot(x1_vals, x2_vals, color='black', linestyle='--', label='Fronteira de Decis√£o')
else:
    # Caso especial: reta vertical
    x_val = -bias / pesos[0]
    plt.axvline(x=x_val, color='black', linestyle='--', label='Fronteira de Decis√£o')

plt.legend()
plt.grid(True)
plt.show()

"""##2.7. An√°lise da Fronteira de Decis√£o
###Interpreta√ß√£o geom√©trica dos pesos como coeficientes da reta
Ap√≥s o treinamento, os pesos $w_1$, $w_2$ e o bias $b$ do Perceptron podem ser interpretados geometricamente como os coeficientes da equa√ß√£o de uma reta no plano cartesiano:

$w_1 x_1 + w_2 x_2 + b = 0$

Reescrevendo para isolar $x_2$:

$x_2 = -\dfrac{w_1}{w_2} x_1 - \dfrac{b}{w_2}$

Essa √© a equa√ß√£o de uma reta com:

- Inclina√ß√£o (coeficiente angular): $-\dfrac{w_1}{w_2}$
- Intercepto com o eixo $x_2$: $-\dfrac{b}{w_2}$

###Como a reta se ajusta para classificar corretamente os dados
Durante o treinamento, a reta de decis√£o √© ajustada alterando os pesos. A cada erro cometido, o algoritmo atualiza os valores de $w_1$, $w_2$ e $b$, movendo e rotacionando a reta at√© que ela divida corretamente os pontos das duas classes.

A reta define regi√µes da seguinte forma:

- Se $w_1 x_1 + w_2 x_2 + b \geq 0$, a sa√≠da $y = 1$
- Se $w_1 x_1 + w_2 x_2 + b < 0$, a sa√≠da $y = 0$

###Demonstra√ß√£o com matplotlib (sem bibliotecas de IA)

Abaixo, mostramos graficamente a reta aprendida e como ela separa os dados no plano bidimensional.

"""

import matplotlib.pyplot as plt

# Preparar dados por classe para plotar com cores diferentes
classe_0 = entradas[saidas == 0]
classe_1 = entradas[saidas == 1]

# Recriar a anima√ß√£o no mesmo estilo do c√≥digo de dispers√£o e reta final

fig, ax = plt.subplots(figsize=(7, 6))
ax.set_xlim(-0.1, 1.1)
ax.set_ylim(-0.1, 1.1)
ax.set_xlabel("$x_1$")
ax.set_ylabel("$x_2$")
ax.set_title("Dispers√£o dos Dados e Evolu√ß√£o da Fronteira de Decis√£o (OR)")
ax.grid(True)

# Dados das classes
classe_0 = entradas[saidas == 0]
classe_1 = entradas[saidas == 1]
ax.scatter(classe_0[:, 0], classe_0[:, 1], color='red', label='Classe 0 (Sa√≠da = 0)')
ax.scatter(classe_1[:, 0], classe_1[:, 1], color='blue', label='Classe 1 (Sa√≠da = 1)')

# Elementos din√¢micos da anima√ß√£o
linha, = ax.plot([], [], 'k--', label='Fronteira de Decis√£o')
epoca_txt = ax.text(0.02, 1.08, '', transform=ax.transAxes)
ax.legend()

# Fun√ß√£o de atualiza√ß√£o por √©poca
def update_anim(epoch):
    w = historico_pesos[epoch]
    b = bias  # usando o bias final (n√£o foi salvo por √©poca)
    epoca_txt.set_text(f"√âpoca: {epoch + 1}")
    if w[1] != 0:
        x_vals = np.linspace(-0.1, 1.1, 100)
        y_vals = -(w[0] * x_vals + b) / w[1]
        linha.set_data(x_vals, y_vals)
    else:
        x_val = -b / w[0]
        linha.set_data([x_val, x_val], [-0.1, 1.1])
    return linha, epoca_txt

# Criar e exibir anima√ß√£o
anim_final = FuncAnimation(fig, update_anim, frames=len(historico_pesos), interval=800, blit=True)
plt.close()
HTML(anim_final.to_jshtml())

"""###Simula√ß√£o do AND"""

# Redefinir tudo para o problema l√≥gico AND

# Dataset AND
entradas_and = np.array([
    [0, 0],
    [0, 1],
    [1, 0],
    [1, 1]
])
saidas_and = np.array([0, 0, 0, 1])

# Reconfigurar par√¢metros
epocas = 20
eta = 0.1
n_amostras, n_entradas = entradas_and.shape
pesos = np.random.uniform(-1, 1, size=n_entradas)  # pesos aleat√≥rios
bias = np.random.uniform(-1, 1)  # bias aleat√≥rio

# Hist√≥rico
historico_pesos = []
historico_erro = []

# Fun√ß√£o de ativa√ß√£o
def degrau(u):
    return 1 if u >= 0 else 0

# Treinamento
for epoca in range(epocas):
    erro_total = 0
    for i in range(n_amostras):
        x = entradas_and[i]
        y_real = saidas_and[i]
        u = np.sum(x * pesos) + bias
        y_pred = degrau(u)
        erro = y_real - y_pred
        erro_total += abs(erro)
        for j in range(n_entradas):
            pesos[j] += eta * erro * x[j]
        bias += eta * erro
    historico_pesos.append(pesos.copy())
    historico_erro.append(erro_total)
    if erro_total == 0:
        break

# Anima√ß√£o da reta (AND)
fig, ax = plt.subplots(figsize=(7, 6))
ax.set_xlim(-0.1, 1.1)
ax.set_ylim(-0.1, 1.1)
ax.set_xlabel("$x_1$")
ax.set_ylabel("$x_2$")
ax.set_title("Dispers√£o dos Dados e Evolu√ß√£o da Fronteira de Decis√£o (AND)")
ax.grid(True)

# Separar as classes
classe_0 = entradas_and[saidas_and == 0]
classe_1 = entradas_and[saidas_and == 1]
ax.scatter(classe_0[:, 0], classe_0[:, 1], color='red', label='Classe 0 (Sa√≠da = 0)')
ax.scatter(classe_1[:, 0], classe_1[:, 1], color='blue', label='Classe 1 (Sa√≠da = 1)')

linha, = ax.plot([], [], 'k--', label='Fronteira de Decis√£o')
epoca_txt = ax.text(0.02, 1.08, '', transform=ax.transAxes)
ax.legend()

def update_and(epoch):
    w = historico_pesos[epoch]
    b = bias  # bias final
    epoca_txt.set_text(f"√âpoca: {epoch + 1}")
    if w[1] != 0:
        x_vals = np.linspace(-0.1, 1.4, 100)
        y_vals = -(w[0] * x_vals + b) / w[1]
        linha.set_data(x_vals, y_vals)
    else:
        x_val = -b / w[0]
        linha.set_data([x_val, x_val], [-0.1, 1.1])
    return linha, epoca_txt

anim_and = FuncAnimation(fig, update_and, frames=len(historico_pesos), interval=800, blit=True)
plt.close()
HTML(anim_and.to_jshtml())

"""##2.8. Discuss√£o dos Resultados
###Por que o Perceptron funciona para OR e AND?
O Perceptron resolve corretamente os problemas l√≥gicos OR e AND porque ambos s√£o **linearmente separ√°veis**. Isso significa que √© poss√≠vel tra√ßar uma **reta (fronteira de decis√£o)** que divide perfeitamente os pontos das duas classes no plano cartesiano.

- No caso do OR, a sa√≠da √© 1 se pelo menos uma das entradas for 1.
- No caso do AND, a sa√≠da √© 1 somente quando **ambas** as entradas forem 1.

Em ambos os casos, o modelo consegue **ajustar os pesos e bias** de forma que a fun√ß√£o de ativa√ß√£o classifique corretamente todas as amostras.


###Influ√™ncia da taxa de aprendizado e n√∫mero de √©pocas
A taxa de aprendizado ($\eta$) define o tamanho do passo na atualiza√ß√£o dos pesos a cada erro cometido. Valores diferentes afetam o comportamento do treinamento:

- $\eta$ muito pequeno: aprendizagem lenta (leva muitas √©pocas para convergir)
- $\eta$ muito alto: pode causar oscila√ß√£o e dificultar a converg√™ncia

O n√∫mero m√°ximo de √©pocas define at√© quando o modelo tenta aprender. Se for muito baixo, o modelo pode n√£o ter tempo suficiente para ajustar corretamente os pesos. Por isso, √© importante equilibrar $\eta$ e o n√∫mero de √©pocas.

---

###Limita√ß√µes do modelo simples mesmo em problemas lineares (por ex., quando dados ruidosos s√£o inseridos)
Mesmo sendo eficiente para problemas simples e lineares, o Perceptron **tem limita√ß√µes** importantes:

- **N√£o consegue aprender padr√µes n√£o-lineares**, como o problema **XOR**
- √â sens√≠vel a **ru√≠do nos dados**: se os pontos n√£o forem perfeitamente separ√°veis, o modelo pode nunca convergir
- Usa uma **fun√ß√£o de ativa√ß√£o n√£o diferenci√°vel (degrau)**, o que impede a utiliza√ß√£o de m√©todos de otimiza√ß√£o mais sofisticados como o gradiente descendente

Essas limita√ß√µes levaram ao desenvolvimento de modelos mais avan√ßados, como as **Redes Neurais Multicamadas (MLPs)**, capazes de resolver problemas mais complexos.

#3. Discuss√£o do problema XOR e suas implica√ß√µes para a evolu√ß√£o das Redes Neurais

##3.1. Revis√£o do Problema L√≥gico XOR
###Tabela verdade do operador XOR

| $x_1$ | $x_2$ | $y$ = $x_1$ ‚äï $x_2$ |
|:-----:|:-----:|:---------------------:|
|  0    |  0    |          0           |
|  0    |  1    |          1           |
|  1    |  0    |          1           |
|  1    |  1    |          0           |

###Interpreta√ß√£o l√≥gica:
O operador XOR (ou "OU exclusivo") retorna 1 somente quando as entradas s√£o diferentes.  
Ou seja:

- Se $x_1 \neq x_2$ ent√£o $y = 1$
- Se $x_1 = x_2$ ent√£o $y = 0$

###Representa√ß√£o gr√°fica: pontos no plano cartesiano
No plano cartesiano, os pontos positivos e negativos **n√£o podem ser separados por uma √∫nica reta**. Isso significa que o problema **XOR n√£o √© linearmente separ√°vel** ‚Äî √© justamente o exemplo cl√°ssico que exp√µe as limita√ß√µes do Perceptron simples.

Abaixo, vamos construir o dataset manualmente e visualizar essa impossibilidade geometricamente.

O conjunto de dados para o problema XOR cont√©m todas as combina√ß√µes bin√°rias de duas entradas, com suas respectivas sa√≠das conforme a opera√ß√£o l√≥gica XOR:

- Entrada: $[0, 0]$ ‚Üí Sa√≠da esperada: $0$
- Entrada: $[0, 1]$ ‚Üí Sa√≠da esperada: $1$
- Entrada: $[1, 0]$ ‚Üí Sa√≠da esperada: $1$
- Entrada: $[1, 1]$ ‚Üí Sa√≠da esperada: $0$

Vamos representar graficamente os pontos:

- Pontos com sa√≠da $y = 1$ ser√£o destacados em azul
- Pontos com sa√≠da $y = 0$ em vermelho

Essa visualiza√ß√£o mostrar√° que **n√£o h√° como separar as duas classes com uma √∫nica linha reta**, destacando a **inadequa√ß√£o do Perceptron simples** para esse tipo de problema.
"""

import matplotlib.pyplot as plt
import numpy as np

# Dataset XOR: entradas e sa√≠das esperadas
entradas_xor = np.array([
    [0, 0],
    [0, 1],
    [1, 0],
    [1, 1]
])
saidas_xor = np.array([0, 1, 1, 0])

# Separar classes para visualiza√ß√£o
classe_0 = entradas_xor[saidas_xor == 0]
classe_1 = entradas_xor[saidas_xor == 1]

# Criar gr√°fico novamente com seta indicativa de tentativa de separa√ß√£o
plt.figure(figsize=(6, 6))
plt.scatter(classe_0[:, 0], classe_0[:, 1], color='red', label='Classe 0 (Sa√≠da = 0)')
plt.scatter(classe_1[:, 0], classe_1[:, 1], color='blue', label='Classe 1 (Sa√≠da = 1)')

# Tentativa de separa√ß√£o com seta (visualiza√ß√£o incorreta intencional)
plt.arrow(0.2, 1.2, 0.6, -1.2, head_width=0.00, head_length=0.1, fc='gray', ec='gray', linestyle='--')
plt.text(0.5, 1.25, "Tentativa de separa√ß√£o", fontsize=10, color='gray')

plt.title("Visualiza√ß√£o do Problema XOR com Tentativa de Separa√ß√£o Linear")
plt.xlabel("$x_1$")
plt.ylabel("$x_2$")
plt.xlim(-0.1, 1.1)
plt.ylim(-0.1, 1.3)
plt.grid(True)
plt.legend()
plt.show()

"""##3.3. Testando o Perceptron no XOR
###Utiliza√ß√£o da mesma implementa√ß√£o do Perceptron simples
Nesta etapa, aplicamos a **mesma implementa√ß√£o do Perceptron** usada nos problemas OR e AND, sem qualquer modifica√ß√£o, para verificar seu desempenho no problema l√≥gico XOR.

###Treinamento com os dados do XOR
Utilizamos o conjunto:

- Entradas: combina√ß√µes bin√°rias de duas vari√°veis
- Sa√≠das esperadas: 0 quando as entradas s√£o iguais, 1 quando s√£o diferentes

Apesar de o treinamento ocorrer normalmente (com atualiza√ß√£o de pesos e bias a cada erro), o modelo **n√£o consegue convergir**, pois os dados **n√£o s√£o linearmente separ√°veis**.

###Resultados obtidos: falhas na classifica√ß√£o correta

Isso evidencia a **limita√ß√£o do modelo simples** diante de problemas n√£o-lineares, como √© o caso do XOR.

> A solu√ß√£o para esse tipo de problema s√≥ √© poss√≠vel com modelos mais robustos, como **redes neurais multicamadas (MLP)** com fun√ß√µes de ativa√ß√£o n√£o-lineares.

Pode ser visto os resultados abaixo:
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from IPython.display import HTML

# Dataset XOR
entradas_xor = np.array([
    [0, 0],
    [0, 1],
    [1, 0],
    [1, 1]
])
saidas_xor = np.array([0, 1, 1, 0])

# Par√¢metros
epocas = 20
eta = 0.1
n_amostras, n_entradas = entradas_xor.shape
#np.random.seed(-1) #para reprotutibilidade
pesos = np.random.uniform(-1, 1, size=n_entradas)
bias = np.random.uniform(-1, 1)

# Hist√≥rico
historico_pesos_xor = []
historico_erro_xor = []

def degrau(u):
    return 1 if u >= 0 else 0

# Treinamento
for epoca in range(epocas):
    erro_total = 0
    for i in range(n_amostras):
        x = entradas_xor[i]
        y_real = saidas_xor[i]
        u = np.sum(x * pesos) + bias
        y_pred = degrau(u)
        erro = y_real - y_pred
        erro_total += abs(erro)
        for j in range(n_entradas):
            pesos[j] += eta * erro * x[j]
        bias += eta * erro
    historico_pesos_xor.append(pesos.copy())
    historico_erro_xor.append(erro_total)

# === Mostrar a reta final que o Perceptron tentou usar ===
classe_0 = entradas_xor[saidas_xor == 0]
classe_1 = entradas_xor[saidas_xor == 1]

fig_final, ax_final = plt.subplots(figsize=(6, 6))
ax_final.set_xlim(-0.1, 1.1)
ax_final.set_ylim(-0.1, 1.1)
ax_final.set_xlabel("$x_1$")
ax_final.set_ylabel("$x_2$")
ax_final.set_title("Reta Final do Perceptron (XOR)")
ax_final.grid(True)
ax_final.scatter(classe_0[:, 0], classe_0[:, 1], color='red', label='Classe 0')
ax_final.scatter(classe_1[:, 0], classe_1[:, 1], color='blue', label='Classe 1')

if pesos[1] != 0:
    x_vals = np.linspace(-0.1, 1.1, 100)
    y_vals = -(pesos[0] * x_vals + bias) / pesos[1]
    ax_final.plot(x_vals, y_vals, 'k--', label='Fronteira Final')
else:
    x_val = -bias / pesos[0]
    ax_final.axvline(x=x_val, color='black', linestyle='--', label='Fronteira Final')
ax_final.legend()
plt.show()

# === Visualizar o gr√°fico de erro por √©poca ===
plt.figure(figsize=(6, 4))
plt.plot(historico_erro_xor, marker='o', color='darkred')
plt.title("Erro Total por √âpoca - Treinamento com XOR")
plt.xlabel("√âpoca")
plt.ylabel("Erro Total")
plt.grid(True)
plt.show()

# === Gerar uma anima√ß√£o com a evolu√ß√£o da reta no XOR ===
fig_anim, ax_anim = plt.subplots(figsize=(6, 6))
ax_anim.set_xlim(-0.1, 1.1)
ax_anim.set_ylim(-0.1, 1.1)
ax_anim.set_xlabel("$x_1$")
ax_anim.set_ylabel("$x_2$")
ax_anim.set_title("Evolu√ß√£o da Fronteira de Decis√£o (XOR)")
ax_anim.grid(True)
ax_anim.scatter(classe_0[:, 0], classe_0[:, 1], color='red', label='Classe 0')
ax_anim.scatter(classe_1[:, 0], classe_1[:, 1], color='blue', label='Classe 1')
linha, = ax_anim.plot([], [], 'k--')
epoca_txt = ax_anim.text(0.02, 1.08, '', transform=ax_anim.transAxes)
ax_anim.legend()

def update(epoch):
    w = historico_pesos_xor[epoch]
    b = bias  # utilizando o bias final
    epoca_txt.set_text(f"√âpoca: {epoch + 1}")
    if w[1] != 0:
        x_vals = np.linspace(-0.1, 1.1, 100)
        y_vals = -(w[0] * x_vals + b) / w[1]
        linha.set_data(x_vals, y_vals)
    else:
        x_val = -b / w[0]
        linha.set_data([x_val, x_val], [-0.1, 1.1])
    return linha, epoca_txt

anim = FuncAnimation(fig_anim, update, frames=len(historico_pesos_xor), interval=800, blit=True)
plt.close()
HTML(anim.to_jshtml())

"""3.4. Visualiza√ß√£o da Falha do Perceptron
Gr√°fico mostrando que os dados n√£o s√£o linearmente separ√°veis

Tentativas frustradas de ajustar uma reta que separe os dados

Ilustra√ß√£o clara da limita√ß√£o do modelo linear

3.5. Entendendo a Limita√ß√£o Te√≥rica
Conceito de linear separability

Prova informal de que XOR n√£o pode ser separado com uma √∫nica reta

Implica√ß√£o direta: Perceptron simples n√£o √© suficiente

3.6. Implica√ß√µes Hist√≥ricas e Cient√≠ficas
Impacto da cr√≠tica de Minsky & Papert (1969) sobre o Perceptron

Queda do interesse em redes neurais na d√©cada de 1970 (inverno da IA)

Redescoberta e evolu√ß√£o nos anos 1980 com o surgimento do Backpropagation

3.7. Solu√ß√£o: Redes Neurais Multicamadas (MLP)
Introdu√ß√£o ao conceito de camada oculta

Como uma MLP pode resolver o XOR

Antecipa√ß√£o do pr√≥ximo passo na evolu√ß√£o das RNAs

3.8. Conclus√£o e Conex√£o com o Futuro
O problema XOR como marco hist√≥rico e ponto de virada

Import√¢ncia da limita√ß√£o para o avan√ßo cient√≠fico

Encaminhamento para estudos sobre redes multicamadas e deep learning
"""



"""#Refer√™ncias
MCCULLOCH, Warren S.; PITTS, Walter. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics, v. 5, p. 115‚Äì133, 1943. Reimpresso em: Bulletin of Mathematical Biology, v. 52, n. 1/2, p. 99‚Äì115, 1990.

ROSENBLATT, Frank. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological Review, v. 65, n. 6, p. 386‚Äì408, 1958.

RUMELHART, David E.; HINTON, Geoffrey E.; MCCLELLAND, James L. Learning internal representations by error propagation. In: RUMELHART, D. E.; MCCLELLAND, J. L.; PDP Research Group (Ed.). Parallel Distributed Processing: Explorations in the Microstructure of Cognition. v. 1: Foundations. Cambridge, MA: MIT Press, 1986. p. 318‚Äì362.

Du, K.-L.; Leung, C.-S.; Mow, W.H.; Swamy, M.N.S. Perceptron: Learning, Generalization, Model Selection, Fault Tolerance, and Role in the Deep Learning Era. Mathematics 2022, 10, 4730. https://doi.org/10.3390/math10244730
"""